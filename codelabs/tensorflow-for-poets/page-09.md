# Time for a Quiz!

> **Instructions**: 
> * Please answer **all** of the questions below.
> * Submit your answers in a file named, `answers.txt`, as part of your GitHub repo.
> * List your answers following the sample format below. (Note: No spaces between question number & answer)
> * Letter answers must be **capitalized**.
>
> **answers.txt** 
> ```
> 1.A
> 2.B
> 3.C
> .
> .
> .
> 10.D
> ```

### Questions
1. What is the open source library for numerical computation, specializing in machine learning applications, made by Google?
	* **[A]** TensorFlow
	* **[B]** Theano
	* **[C]** Keras

2. It is a way that allows you to start with a model that has been already trained on another problem.
	* **[A]** Reinforcement Learning
	* **[B]** Machine Learning
	* **[C]** Transfer Learning

3. This particular model is optimized to be small and efficient, at the cost of some accuracy.
	* **[A]** Convolutional Neural Networks
	* **[B]** MobileNet
	* **[C]** Inception V3

4. This particular model has a first-choice accuracy of 78% on ImageNet.
	* **[A]** Convolutional Neural Networks
	* **[B]** MobileNet
	* **[C]** Inception V3

5. When retraining, the retraining script writes data to this file which contains a version of the selected network with a final layer retrained on your categories.
	* **[A]** `tf_files/retrained_graph.pb`
	* **[B]** `tf_files/retrained_labels.txt`
	* **[C]** `tf_files/label_image.py`

6. This parameter controls the magnitude of the updates to the final layer during training.
	* **[A]** `--learning_rate`
	* **[B]** `--summaries_dir`
	* **[C]** `--how_many_training_steps`

7. When retraining, the retraining script writes data to this file which is a text file containing labels.
	* **[A]** `tf_files/retrained_graph.pb`
	* **[B]** `tf_files/retrained_labels.txt`
	* **[C]** `tf_files/label_image.txt`

8. It is the option that controls the name in tensorboard.
	* **[A]** `--learning_rate`
	* **[B]** `--summaries_dir`
	* **[C]** `--image_dir`

9. It is an informal term we often use for the layer just before the final output layer that actually does the classification.
	* **[A]** Softmax
	* **[B]** Prediction
	* **[C]** Bottleneck

10. It is a loss function that gives a glimpse into how well the learning process is progressing.
	* **[A]** Cross Entropy
	* **[B]** Unified Loss
	* **[C]** Hinge Loss